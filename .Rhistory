table(d17a.svm$fitted, d17a$y)
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=0))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]-<1
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=0))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]<-1
}
dat$y<-as.factor(dat$y)
d17a.tune = tune(y~., data=d17a, kernel="radial", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)), gamma=1)
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=0))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]<-1
}
plot(x, col=(3-y))
View(dat)
plot(x, col=(3-dat$y))
set.seed(1) # This sets the randomization seed.
x=matrix(rnorm(250*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
x[201:250,2]=x[201:250,2]+2
y=c(rep(1,150),rep(2,50),rep(0,50))
d17a = data.frame(x=x, y=as.factor(y))
d17a.tune = tune(y~., data=d17a, kernel="radial", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)), gamma=1)
d17a.tune = tune(svm,y~., data=d17a, kernel="radial", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)), gamma=1)
summary(d17a.tune)
d17a.tune = tune(svm,y~., data=d17a, kernel="radial", ranges=list(gamma=c(.5, 1, 2, 3, 4,5)), cost=1)
summary(d17a.tune)
d17a.tune = tune(svm,y~., data=d17a, kernel="polynomial", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)))
summary(d17a.tune)
d17a.tune = tune(svm,y~., data=d17a, kernel="polynomial", ranges=list(degree=c(1,2,3,4,5)), cost=100)
summary(d17a.tune)
d17a.tune = tune(svm,y~., data=d17a, kernel="linear", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)))
summar(d17a.tune)
summart(d17a.tune)
summary(d17a.tune)
library(FNN)
x <- matrix(rnorm(20*2), ncol=2)
y <- c(rep(-1,10),rep(1,10))
x[y==1,] <- x[y==1,]+1         #creates data such that two classes are barely linearly separable
x[y==1,] <- x[y==1,]+.05
plot(x, col=(3-y))
dat<-data.frame(x=x, y=as.factor(y))
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=0))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
for(i in 1:nrow(dat)) {
if(dat[i,1]>-dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>-1*dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
kk
}
### C
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(x, col=(3-test$y))
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
x <- matrix(rnorm(20*2), ncol=2)
y <- c(rep(-1,10),rep(1,10))
x[y==1,] <- x[y==1,]+1         #creates data such that two classes are barely linearly separable
x[y==1,] <- x[y==1,]+.05
plot(x, col=(3-y))
dat<-data.frame(x=x, y=as.factor(y))
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x <- matrix(rnorm(20*2), ncol=2)
y <- c(rep(-1,10),rep(1,10))
x[y==1,] <- x[y==1,]+1         #creates data such that two classes are barely linearly separable
x[y==1,] <- x[y==1,]+.05
plot(x, col=(3-y))
test<-data.frame(x=x, y=as.factor(y))
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
install.packages("superpc")
library(superpc)
set.seed(464)
x <- matrix(rnorm(1000*100), ncol = 100)
v1 <- svd(x[1:80, ])$v[ , 1]
y <- 2 + 5  *v1 + .05*rnorm(100)
xtest <- x
ytest <- 2 + 5*v1 + .05*rnorm(100)
censoring.status <- sample(c(rep(1, 80), rep(0, 20)))
censoring.status.test <- sample(c(rep(1, 80), rep(0, 20)))
featurenames <- paste("feature", as.character(1:1000), sep = "")
data <- list(x = x, y = y, censoring.status = censoring.status, featurenames = featurenames)
data.test <- list(x = xtest, y = ytest, censoring.status = censoring.status.test,
featurenames = featurenames)
# Train  the model. This step just computes the  scores for each feature.
train.obj <- superpc.train(data, type = "survival")
head(train.obj$feature.scores)
# Note for regression (non-survival) data, we leave the component "censoring.status"
# out of the data object, and call superpc.train with type = "regression".
# otherwise the superpc commands are all the same
##### Cross-validation #####
# Cross-validate the model in order to determine the best threshold
cv.obj <- superpc.cv(train.obj, data)
# Plot the cross-validation curves. From this plot we see that the 1st
# principal component is significant and the best threshold is around 0.7.
superpc.plotcv(cv.obj)
abline(v = 0.7)
lrtest.obj <- superpc.lrtest.curv(train.obj, data, data.test)
superpc.plot.lrtest(lrtest.obj)
abline(v = 0.7)
fit.cts <- superpc.predict(train.obj, data, data.test, threshold = 0.7, n.components = 3,
prediction.type = "continuous")
superpc.fit.to.outcome(train.obj, data.test, fit.cts$v.pred)
fit.groups <- superpc.predict(train.obj, data, data.test, threshold = 0.7,
n.components = 1, prediction.type = "discrete")
superpc.fit.to.outcome(train.obj, data.test, fit.groups$v.pred)
plot(survfit(Surv(data.test$y, data.test$censoring.status) ~ fit.groups$v.pred),
col = 2:3, xlab = "time", ylab = "Prob survival", main = "Kaplan-Meier Curve")
fit.red <- superpc.predict.red(train.obj, data, data.test, threshold = 0.7)
superpc.plotred.lrtest(fit.red)
fit.redcv <- superpc.predict.red.cv(fit.red, cv.obj, data, threshold = 0.7)
superpc.plotred.lrtest(fit.redcv)
# Finally we list the significant genes, in order of decreasing importance score
list_feat <- superpc.listfeatures(data.test, train.obj, fit.red, fitred.cv = fit.redcv)
summary(list_feat)
setwd("~/Documents/!Research/Github/NBA")
setwd("~/Documents/!Research/Github/NBA")
train<-read.csv("train515.csv")
train<-read.csv("data515.csv")
train_515r=train[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
train_515r=cbind(train_515r[,-ncol(train_515r)], yvar=train_515r[,"Win_5"])
p2.model<-svm(yvar~., data=train_515r, kernel="linear", cost=.01)     #have to update cost/gamma/degree.  linear, radial, polynomial, possibly train.p2a
library(e1071)
fit_svm.l<-function(train, cost_vect) {
library(e1071)
tune.linear<-tune(svm, yvar~., data=train, kernel="linear", ranges=list(cost=cost_vect))
param<-tune.linear$best.parameters
acc<-1-tune.linear$best.performance
return (data.frame(acc, method=paste0("svc, cost:", param[1])))
}
train<-read.csv("data515.csv")
train_515r=train[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
train_515r=cbind(train_515r[,-ncol(train_515r)], yvar=train_515r[,"Win_5"])
p2.model<-svm(yvar~., data=train_515r, kernel="linear", cost=.01)     #have to update cost/gamma/degree.  linear, radial, polynomial, possibly train.p2a
fit_svm.l(train_515r, c(.001, .01 .1, 1, 5, 25))
fit_svm.l(train_515r, c(.001, .01, .1, 1, 5, 25))
test<-read.csv('data515test.csv')
test_full<-read.csv('data515test.csv')
test=test_full[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
predvect<-predict(p2.model, newdata=test)
predvect
predvect[predvect> .5] <- 1
predvect[predvect<=.5] <-0
predvect<-cbind(predvect, test[,c("Win_5", "Game_ID")])
test_full<-read.csv('data515test.csv')
test=test_full[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
predvect<-predict(p2.model, newdata=test)
predvect[predvect> .5] <- 1
predvect[predvect<=.5] <-0
predvect<-cbind(predvect, test[,c("Win_5", "Game_ID")])
test_full<-read.csv('data515test.csv')
test=test_full[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
predvect<-predict(p2.model, newdata=test)
predvect[predvect> .5] <- 1
predvect[predvect<=.5] <-0
predvect<-cbind(predvect, test_full[,c("Win_5", "Game_ID")])
table(predvect[,"predvect"], predvect[,"Win_5"])
(86+50)/(50+86+36+34)
test_full<-read.csv('data515.csv')
test=test_full[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
predvect<-predict(p2.model, newdata=test)
predvect[predvect> .5] <- 1
predvect[predvect<=.5] <-0
predvect<-cbind(predvect, test_full[,c("Win_5", "Game_ID")])
table(predvect[,"predvect"], predvect[,"Win_5"])
(282+171)/(282+171+130+84)
predvect<-predict(p2.model, newdata=test)
mean(predvect)
test_full<-read.csv('data515.csv')
test=test_full[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
predvect<-predict(p2.model, newdata=test)
predvect[predvect> .4] <- 1
predvect[predvect<=.4] <-0
predvect<-cbind(predvect, test_full[,c("Win_5", "Game_ID")])
table(predvect[,"predvect"], predvect[,"Win_5"])
(208+245)/(208+245+93+121)
model=tune(svm, yvar~., data=train, kernel='linear', ranges=list(c(.01, .1, 1)))
model=tune(svm, yvar~., data=train515r, kernel='linear', ranges=list(c(.01, .1, 1)))
model=tune(svm, yvar~., data=train_515r, kernel='linear', ranges=list(c(.01, .1, 1)))
model
summary(model)
p2.model<-svm(yvar~., data=train_515r, kernel="linear", cost=.01, type="C")     #have to update cost/gamma/degree.  linear, radial, polynomial, possibly train.p2a
test_full<-read.csv('data515.csv')
test=test_full[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
predvect<-predict(p2.model, newdata=test)
predvect[predvect> .4] <- 1
predvect<-cbind(predvect, test_full[,c("Win_5", "Game_ID")])
table(predvect[,"predvect"], predvect[,"Win_5"])
(170+286)/(170+286+80+131)
test_full<-read.csv('data515.csv')
test=test_full[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
predvect<-predict(p2.model, newdata=test)
predvect
fit_svm.l<-function(train, cost_vect) {
library(e1071)
tune.linear<-tune(svm, yvar~., data=train, kernel="linear", ranges=list(cost=cost_vect), type="C")
param<-tune.linear$best.parameters
acc<-1-tune.linear$best.performance
return (data.frame(acc, method=paste0("svc, cost:", param[1])))
}
fit_svm.l(train_515r, c(.001, .01, .1, 1, 5, 25))
train<-read.csv("data515.csv")
train_515r=train[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
train_515r=cbind(train_515r[,-ncol(train_515r)], yvar=as.factor(train_515r[,"Win_5"])
fit_svm.l(train_515r, c(.001, .01, .1, 1, 5, 25))
train<-read.csv("data515.csv")
train_515r=train[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
train_515r=cbind(train_515r[,-ncol(train_515r)], yvar=as.factor(train_515r[,"Win_5"]))
p2.model<-svm(yvar~., data=train_515r, kernel="linear", cost=.01, type="C")     #have to update cost/gamma/degree.  linear, radial, polynomial, possibly train.p2a
test_full<-read.csv('data515.csv')
test=test_full[,c("Def.FTFGA_a_5", "EFG_a_5", "EFG_h_15", "Win.Pct_a_15", "Win.Pct_h_15", "Def.EFG_h_15", "Def.TOV_h_15", "FTFGA_h_15", "TOV_h_15", "Win_5")]
predvect<-predict(p2.model, newdata=test)
predvect<-cbind(predvect, test_full[,c("Win_5", "Game_ID")])
table(predvect[,"predvect"], predvect[,"Win_5"])
fit_svm.l<-function(train, cost_vect) {
library(e1071)
tune.linear<-tune(svm, yvar~., data=train, kernel="linear", ranges=list(cost=cost_vect), type="C")
param<-tune.linear$best.parameters
acc<-1-tune.linear$best.performance
return (data.frame(acc, method=paste0("svc, cost:", param[1])))
}
fit_svm.l(train_515r, c(.001, .01, .1, 1, 5, 25))
fit_svm.l(train_515r, c(.001, .01, .1, 1, 5, 25))
