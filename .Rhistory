ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #ranges is list of possible costs, which is a big range
set.seed(1) # This set randomization seed.
x <- matrix(rnorm(20*2), ncol=2)
y <- c(rep(-1,10),rep(1,10))
x[y==1,] <- x[y==1,]+1  # Add 1 to x-values with y = 1.
plot(x, col=(3-y), pch=20,cex=.8)  # Color classes red, blue
# We can see that the classes are not quite linearly separable.
# Let's try a support vector classifier.
# The package/library "e1071" will be used in what
# follows, so we download and install it now.
install.packages("e1071")
library(e1071)
d16a <- data.frame(x=x, y=as.factor(y))
# Setting y as a factor will cause svm to perform classification
# instead of regression.
d16a.svm <- svm(y~., data=d16a, kernel="linear", cost=10, scale=FALSE)
plot(d16a.svm, d16a) # There are 7 support vectors (X's); one misclassified
d16a.svm$index  # The indices for the support vectors.
summary(d16a.svm)
d16a.svm <- svm(y~., data=d16a, kernel="linear", cost=0.1, scale=FALSE)
plot(d16a.svm, d16a) # There are 7 support vectors (X's); one misclassified
d16a.svm$index  # The indices
set.seed(1)
d16a.tune <- tune(svm, y~., data=d16a, kernel="linear",
ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #ranges is list of possible costs, which is a big range
tune.out=tune(svm,y∼.,data=dat,kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
dat
tune.out=tune(svm,y∼.,data=dat,kernel="linear", ranges=list(cost=c(0.0001,0.001, 0.01, 0.1, 1,5,10,100)))
tune=tune(svm,y∼.,data=dat,kernel="linear", ranges=list(cost=c(0.0001,0.001, 0.01, 0.1, 1,5,10,100)))
tune<-tune(svm,y∼.,data=dat,kernel="linear", ranges=list(cost=c(0.0001,0.001, 0.01, 0.1, 1,5,10,100)))
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))
install.packages("e1071")
install.packages("e1071")
library(e1071)
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))
tune<-tune(svm,y∼.,data=dat,kernel="linear",    ranges=list(cost=c(0.0001,0.001, 0.01, 0.1, 1,5,10,100)))
tune<-tune(svm,y∼x,data=dat,kernel="linear",    ranges=list(cost=c(0.0001,0.001, 0.01, 0.1, 1,5,10,100)))
tune<-tune(svm,data=dat,kernel="linear",    ranges=list(cost=c(0.0001,0.001, 0.01, 0.1, 1,5,10,100)))
tune<-tune(svm,y~.,data=dat,kernel="linear",    ranges=list(cost=c(0.0001,0.001, 0.01, 0.1, 1,5,10,100)))
set.seed(1) # This sets the randomization seed.
x=matrix(rnorm(250*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
x[201:250,2]=x[201:250,2]+2
y=c(rep(1,150),rep(2,50),rep(0,50))
d17a = data.frame(x=x, y=as.factor(y))
plot(x, col=(y+1), pch=20,cex=.8)
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=0))
View(dat)
library(e1071)
d17a.svm = svm(y~., data=d17a, kernel="radial", cost=10, gamma=1)
plot(d17a.svm, d17a)
table(d17a.svm$fitted, d17a$y)
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=0))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]-<1
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=0))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]<-1
}
dat$y<-as.factor(dat$y)
d17a.tune = tune(y~., data=d17a, kernel="radial", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)), gamma=1)
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=0))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]<-1
}
plot(x, col=(3-y))
View(dat)
plot(x, col=(3-dat$y))
set.seed(1) # This sets the randomization seed.
x=matrix(rnorm(250*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
x[201:250,2]=x[201:250,2]+2
y=c(rep(1,150),rep(2,50),rep(0,50))
d17a = data.frame(x=x, y=as.factor(y))
d17a.tune = tune(y~., data=d17a, kernel="radial", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)), gamma=1)
d17a.tune = tune(svm,y~., data=d17a, kernel="radial", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)), gamma=1)
summary(d17a.tune)
d17a.tune = tune(svm,y~., data=d17a, kernel="radial", ranges=list(gamma=c(.5, 1, 2, 3, 4,5)), cost=1)
summary(d17a.tune)
d17a.tune = tune(svm,y~., data=d17a, kernel="polynomial", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)))
summary(d17a.tune)
d17a.tune = tune(svm,y~., data=d17a, kernel="polynomial", ranges=list(degree=c(1,2,3,4,5)), cost=100)
summary(d17a.tune)
d17a.tune = tune(svm,y~., data=d17a, kernel="linear", ranges=list(cost=c(.001, .01, .1, 1,10, 50, 100)))
summar(d17a.tune)
summart(d17a.tune)
summary(d17a.tune)
library(FNN)
x <- matrix(rnorm(20*2), ncol=2)
y <- c(rep(-1,10),rep(1,10))
x[y==1,] <- x[y==1,]+1         #creates data such that two classes are barely linearly separable
x[y==1,] <- x[y==1,]+.05
plot(x, col=(3-y))
dat<-data.frame(x=x, y=as.factor(y))
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=0))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,2]>dat[i,1])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
for(i in 1:nrow(dat)) {
if(dat[i,1]>-dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>-1*dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
kk
}
### C
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(x, col=(3-test$y))
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
### A'
x<-matrix(rnorm(20*2), ncol=2)
dat<-data.frame(cbind(x=x, y=-1))
for(i in 1:nrow(dat)) {
if(dat[i,1]>dat[i,2])
dat[i,3]<-1
}
plot(x, col=(3-dat$y))
dat$y<-as.factor(dat$y)
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x.t<-matrix(rnorm(20*2), ncol=2)
test<-data.frame(cbind(x=x.t, y=-1))
for(i in 1:nrow(test)) {
if(test[i,1]>test[i,2])
test[i,3]<-1
}
plot(test$V1~test$V2, col=(3-test$y))
test$y<-as.factor(test$y)
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
x <- matrix(rnorm(20*2), ncol=2)
y <- c(rep(-1,10),rep(1,10))
x[y==1,] <- x[y==1,]+1         #creates data such that two classes are barely linearly separable
x[y==1,] <- x[y==1,]+.05
plot(x, col=(3-y))
dat<-data.frame(x=x, y=as.factor(y))
### B
tune<-tune(svm, y~., data=dat, kernel="linear", ranges=list(cost=c(.0001,.001,.01,.1,1,5,10,20,100)))   #CV for different costs
summary(tune)
bestmod <- tune$best.model
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for training data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=dat[,-3])
err<-sum(pred!=dat[,3])/nrow(dat)
print (paste0("cost: ", c, "  error: ", err))
}
### C  also include old method just in case
x <- matrix(rnorm(20*2), ncol=2)
y <- c(rep(-1,10),rep(1,10))
x[y==1,] <- x[y==1,]+1         #creates data such that two classes are barely linearly separable
x[y==1,] <- x[y==1,]+.05
plot(x, col=(3-y))
test<-data.frame(x=x, y=as.factor(y))
for(c in c(.0001,.001,.01,.1,1,5,10,20,100)) {    #error rates for test data for different costs
svm<-svm(y~., data=dat, cost=c, scale=FALSE)
pred<-predict(svm, newdata=test[,-3])
err<-sum(pred!=test[,3])/nrow(test)
print (paste0("cost: ", c, "  error: ", err))
}
install.packages("superpc")
library(superpc)
set.seed(464)
x <- matrix(rnorm(1000*100), ncol = 100)
v1 <- svd(x[1:80, ])$v[ , 1]
y <- 2 + 5  *v1 + .05*rnorm(100)
xtest <- x
ytest <- 2 + 5*v1 + .05*rnorm(100)
censoring.status <- sample(c(rep(1, 80), rep(0, 20)))
censoring.status.test <- sample(c(rep(1, 80), rep(0, 20)))
featurenames <- paste("feature", as.character(1:1000), sep = "")
data <- list(x = x, y = y, censoring.status = censoring.status, featurenames = featurenames)
data.test <- list(x = xtest, y = ytest, censoring.status = censoring.status.test,
featurenames = featurenames)
# Train  the model. This step just computes the  scores for each feature.
train.obj <- superpc.train(data, type = "survival")
head(train.obj$feature.scores)
# Note for regression (non-survival) data, we leave the component "censoring.status"
# out of the data object, and call superpc.train with type = "regression".
# otherwise the superpc commands are all the same
##### Cross-validation #####
# Cross-validate the model in order to determine the best threshold
cv.obj <- superpc.cv(train.obj, data)
# Plot the cross-validation curves. From this plot we see that the 1st
# principal component is significant and the best threshold is around 0.7.
superpc.plotcv(cv.obj)
abline(v = 0.7)
lrtest.obj <- superpc.lrtest.curv(train.obj, data, data.test)
superpc.plot.lrtest(lrtest.obj)
abline(v = 0.7)
fit.cts <- superpc.predict(train.obj, data, data.test, threshold = 0.7, n.components = 3,
prediction.type = "continuous")
superpc.fit.to.outcome(train.obj, data.test, fit.cts$v.pred)
fit.groups <- superpc.predict(train.obj, data, data.test, threshold = 0.7,
n.components = 1, prediction.type = "discrete")
superpc.fit.to.outcome(train.obj, data.test, fit.groups$v.pred)
plot(survfit(Surv(data.test$y, data.test$censoring.status) ~ fit.groups$v.pred),
col = 2:3, xlab = "time", ylab = "Prob survival", main = "Kaplan-Meier Curve")
fit.red <- superpc.predict.red(train.obj, data, data.test, threshold = 0.7)
superpc.plotred.lrtest(fit.red)
fit.redcv <- superpc.predict.red.cv(fit.red, cv.obj, data, threshold = 0.7)
superpc.plotred.lrtest(fit.redcv)
# Finally we list the significant genes, in order of decreasing importance score
list_feat <- superpc.listfeatures(data.test, train.obj, fit.red, fitred.cv = fit.redcv)
summary(list_feat)
setwd("~/Documents/!Research/Github/NBA")
train<-read.csv("data515.csv")
View(train)
train<-read.csv("data515.csv")
train515=train[,-c('Game_ID', 'Home_5', 'Win_5', 'n.games_a_5', 'n.games_h_5', 'Home_15', 'Win_15')]
train515=train[,select=-c('Game_ID', 'Home_5', 'Win_5', 'n.games_a_5', 'n.games_h_5', 'Home_15', 'Win_15')]
train515=train[,-c('Game_ID', 'Home_5')]
train515=train[,-c(Game_ID, Home_5)]
train<-read.csv("data515.csv")
train515=names(train)[!names(train)%in% c('Game_ID', 'Home_5', 'Win_5', 'n.games_a_5', 'n.games_h_5', 'Home_15', 'Win_15')
train<-read.csv("data515.csv")
train<-read.csv("data515.csv")
train515=names(train)[!names(train)%in% c('Game_ID', 'Home_5', 'Win_5', 'n.games_a_5', 'n.games_h_5', 'Home_15', 'Win_15')]
train515=train[,-which(names(train)%in% c('Game_ID', 'Home_5', 'Win_5', 'n.games_a_5', 'n.games_h_5', 'Home_15', 'Win_15')]
train515=train[,-which(names(train)%in% c('Game_ID', 'Home_5', 'Win_5', 'n.games_a_5', 'n.games_h_5', 'Home_15', 'Win_15'))]
train515=cbind(train515, yvar=train$Win_5)
library(tree)
train515$yvar<-factor(train515$yvar)     #update y variable name
tree.model<-tree(yvar~., train515)       #update y variable name
summary(tree515)
summary(tree.model)
1plot(tree.p1)
plot(tree.model)
text(tree.model, cex=0.2)
text(tree.model, cex=0.5)
plot(tree.model)
text(tree.model, cex=0.5)
prune5 <- prune.misclass(tree.model,best=5)
summary(prune5)
plot(prune5)
text(prune5, cex=0.5)
prune5 <- prune.misclass(tree.model,best=8)
summary(prune5)
plot(prune5)
text(prune5, cex=0.5)
plot(prune5)
text(prune5, cex=1)
prune5 <- prune.misclass(tree.model,best=10)
summary(prune5)
plot(prune5)
text(prune5, cex=1)
prune5 <- prune.misclass(tree.model,best=7)
summary(prune5)
plot(prune5)
text(prune5, cex=1)
prune5 <- prune.misclass(tree.model,best=8)
summary(prune5)
plot(prune5)
text(prune5, cex=1)
ran.model <- randomForest(yvar~., data=train515, mtry=8)
library(randomForest)
ran.model <- randomForest(yvar~., data=train515, mtry=8)
summary(ran.model)
ran.model <- randomForest(yvar~., data=train515, mtry=5)
summary(ran.model)
